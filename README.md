# Enhancing Talking Head Clarity and Smoothness via Optical Flow, Super-Resolution, and Frame Interpolation

## Demos
### GFPGAN: Before and After Comparison
[video1](https://github.com/Xinming-Shu/Talking-Head-FGE/gfpgan_cmp.mp4)

### EMA-VFI: Comparison of Different Interpolation Methods
[video2](https://github.com/Xinming-Shu/Talking-Head-FGE/wav2lip_compare_vfi.mp4)

### Before and After Introducing Optical Flow Constraints
[video3](https://github.com/Xinming-Shu/Talking-Head-FGE/Obama_ft_sr.mp4)


## Acknowledgements
- We use pre-trained Wav2Lip model from [this repository](https://github.com/Rudrabha/Wav2Lip/tree/master/evaluation).
- We use pre-trained FlowNet from [this repository](https://github.com/NVIDIA/flownet2-pytorch).
- We use GFPGAN model from [this repository](https://github.com/TencentARC/GFPGAN).
- We use EMA-VFI from [this repository](https://github.com/MCG-NJU/EMA-VFI).

Thanks to the authors of above repositories.
