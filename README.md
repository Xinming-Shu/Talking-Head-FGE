<div align="center">

# Enhancing Talking Head Clarity and Smoothness via Optical Flow, Super-Resolution, and Frame Interpolation

<div align="center">
  <a href='' target="_blank"><img src='https://img.shields.io/badge/Project-Wav2Lip-FGE-green'></a>
</div>
<br>


## Demos
### GFPGAN: Before and After Comparison
<video controls loop src="" muted="false"></video>
Download: [GFPGAN: Before and After Comparison](https://github.com/Xinming-Shu/Talking-Head-FGE/gfpgan_cmp.mp4)

### EMA-VFI: Comparison of Different Interpolation Methods
Download: [EMA-VFI: Comparison of Different Interpolation Methods](https://github.com/Xinming-Shu/Talking-Head-FGE/wav2lip_compare_vfi.mp4)

### Before and After Introducing Optical Flow Constraints
Download: [Before and After Introducing Optical Flow Constraints](https://github.com/Xinming-Shu/Talking-Head-FGE/Obama_ft_sr.mp4)


## Acknowledgements
- We use pre-trained Wav2Lip model from [this repository](https://github.com/Rudrabha/Wav2Lip/tree/master/evaluation).
- We use pre-trained FlowNet from [this repository](https://github.com/NVIDIA/flownet2-pytorch).
- We use GFPGAN model from [this repository](https://github.com/TencentARC/GFPGAN).
- We use EMA-VFI from [this repository](https://github.com/MCG-NJU/EMA-VFI).

Thanks to the authors of above repositories.
