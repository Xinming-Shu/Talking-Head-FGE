<div align="center">
  <h1>Enhancing Talking Head Clarity and Smoothness via Optical Flow, Super-Resolution, and Frame Interpolation</h1>
</div>

<div align="center">
  <a href='https://xinming-shu.github.io/Talking-Head-FGE/' target="_blank"><img src='https://img.shields.io/badge/Project-TalkingHead_FGE-green'></a>
</div>
<br>


<div align="center">
  <h2>Demos</h2>
</div>

### Super-Resolution: Before and After Comparison
[![Watch the video](https://img.youtube.com/vi/buddCHhOCRI/0.jpg)](https://www.youtube.com/watch?v=buddCHhOCRI)
<br>
Download: [Super-Resolution: Before and After Comparison](https://github.com/Xinming-Shu/Talking-Head-FGE/raw/main/videos/gfpgan_cmp.mp4)

<iframe width="100%" src="https://www.youtube.com/embed/buddCHhOCRI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

[![](https://i.ytimg.com/vi/buddCHhOCRI/maxresdefault.jpg)](https://youtu.be/buddCHhOCRI "")

<iframe width="560" height="315" src="https://www.youtube.com/embed/buddCHhOCRI?si=9mXiUrrh5di9sK39" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### Frame Interpolation: Comparison of Different Interpolation Methods
[![Watch the video](https://img.youtube.com/vi/AwW7XIebQZQ/0.jpg)](https://www.youtube.com/watch?v=AwW7XIebQZQ)
<br>
Download: [Frame Interpolation: Comparison of Different Interpolation Methods](https://github.com/Xinming-Shu/Talking-Head-FGE/raw/main/videos/wav2lip_compare_vfi.mp4)

### Before and After Introducing Optical Flow Constraints
[![Watch the video](https://img.youtube.com/vi/6oN1aJwrHQ8/0.jpg)](https://www.youtube.com/watch?v=6oN1aJwrHQ8)
<br>
Download: [Before and After Introducing Optical Flow Constraints](https://github.com/Xinming-Shu/Talking-Head-FGE/raw/main/videos/Obama_ft_sr.mp4)
<br>
<br>

<div align="center">
  <h2>Acknowledgements</h2>
</div>

- We use pre-trained Wav2Lip model from [this repository](https://github.com/Rudrabha/Wav2Lip/tree/master/evaluation).
- We use pre-trained FlowNet from [this repository](https://github.com/NVIDIA/flownet2-pytorch).
- We use GFPGAN model from [this repository](https://github.com/TencentARC/GFPGAN).
- We use EMA-VFI from [this repository](https://github.com/MCG-NJU/EMA-VFI).

Thanks to the authors of above repositories.
